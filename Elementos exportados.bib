
@article{tian_what_2020,
	title = {What {Makes} for {Good} {Views} for {Contrastive} {Learning}?},
	url = {http://arxiv.org/abs/2005.10243},
	abstract = {Contrastive learning between multiple views of the data has recently achieved state of the art performance in the ﬁeld of self-supervised representation learning. Despite its success, the inﬂuence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classiﬁcation accuracy. As a byproduct, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classiﬁcation (73\% top-1 linear readout with a ResNet-50)1.},
	language = {en},
	urldate = {2021-05-05},
	journal = {arXiv:2005.10243 [cs]},
	author = {Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
	month = dec,
	year = {2020},
	note = {arXiv: 2005.10243},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: NeurIPS 2020. Project page: https://hobbitlong.github.io/InfoMin/},
	file = {Tian et al. - 2020 - What Makes for Good Views for Contrastive Learning.pdf:C\:\\Users\\Javier\\Zotero\\storage\\7XCI74ET\\Tian et al. - 2020 - What Makes for Good Views for Contrastive Learning.pdf:application/pdf},
}
