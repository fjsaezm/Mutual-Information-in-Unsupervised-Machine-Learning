@inproceedings{lowe2019putting,
  title={Putting an End to End-to-End: Gradient-Isolated Learning of Representations},
  author={L{\"o}we, Sindy and O'Connor, Peter and Veeling, Bastiaan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3039--3051},
  year={2019}
}

@article{bengio_representation_2014,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	shorttitle = {Representation {Learning}},
	url = {http://arxiv.org/abs/1206.5538},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	language = {en},
	urldate = {2021-02-14},
	journal = {arXiv:1206.5538 [cs]},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = apr,
	year = {2014},
	note = {arXiv: 1206.5538},
	keywords = {Computer Science - Machine Learning},
	file = {Bengio et al. - 2014 - Representation Learning A Review and New Perspect.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\RU4S3BSM\\Bengio et al. - 2014 - Representation Learning A Review and New Perspect.pdf:application/pdf},
}



@article{wiskott_slow_2002,
	title = {Slow {Feature} {Analysis}: {Unsupervised} {Learning} of {Invariances}},
	volume = {14},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Slow {Feature} {Analysis}},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/089976602317318938},
	doi = {10.1162/089976602317318938},
	abstract = {Invariant features of temporally varying signals are useful for analysis and classification. Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal. It is based on a nonlinear expansion of the input signal and application of principal component analysis to this expanded signal and its time derivative. It is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance. SFA can be applied hierarchically to process high-dimensional input signals and extract complex features. SFA is applied first to complex cell tuning properties based on simple cell output, including disparity and motion. Then more complicated input-output functions are learned by repeated application of SFA. Finally, a hierarchical network of SFA modules is presented as a simple model of the visual system. The same unstructured network can learn translation, size, rotation, contrast, or, to a lesser degree, illumination invariance for one-dimensional objects, depending on only the training stimulus. Surprisingly, only a few training objects suffice to achieve good generalization to new objects. The generated representation is suitable for object recognition. Performance degrades if the network is trained to learn multiple invariances simultaneously.},
	language = {en},
	number = {4},
	urldate = {2021-02-09},
	journal = {Neural Computation},
	author = {Wiskott, Laurenz and Sejnowski, Terrence J.},
	month = apr,
	year = {2002},
	pages = {715--770},
	file = {Wiskott and Sejnowski - 2002 - Slow Feature Analysis Unsupervised Learning of In.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\UM2PKC9K\\Wiskott and Sejnowski - 2002 - Slow Feature Analysis Unsupervised Learning of In.pdf:application/pdf},
}


@article{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	language = {en},
	urldate = {2021-03-09},
	journal = {arXiv:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv: 1301.3781},
	keywords = {Computer Science - Computation and Language},
	file = {Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\NZ8355R7\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf},
}


@article{doersch_unsupervised_2016,
	title = {Unsupervised {Visual} {Representation} {Learning} by {Context} {Prediction}},
	url = {http://arxiv.org/abs/1505.05192},
	abstract = {This work explores the use of spatial context as a source of free and plentiful supervisory signal for training a rich visual representation. Given only a large, unlabeled image collection, we extract random pairs of patches from each image and train a convolutional neural net to predict the position of the second patch relative to the ﬁrst. We argue that doing well on this task requires the model to learn to recognize objects and their parts. We demonstrate that the feature representation learned using this within-image context indeed captures visual similarity across images. For example, this representation allows us to perform unsupervised visual discovery of objects like cats, people, and even birds from the Pascal VOC 2011 detection dataset. Furthermore, we show that the learned ConvNet can be used in the RCNN framework [21] and provides a signiﬁcant boost over a randomly-initialized ConvNet, resulting in state-of-theart performance among algorithms which use only Pascalprovided training set annotations.},
	language = {en},
	urldate = {2021-03-09},
	journal = {arXiv:1505.05192 [cs]},
	author = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A.},
	month = jan,
	year = {2016},
	note = {arXiv: 1505.05192},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}


@article{oord_representation_2019,
	title = {Representation {Learning} with {Contrastive} {Predictive} {Coding}},
	url = {http://arxiv.org/abs/1807.03748},
	abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artiﬁcial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
	language = {en},
	urldate = {2020-12-02},
	journal = {arXiv:1807.03748 [cs, stat]},
	author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	month = jan,
	year = {2019},
	note = {arXiv: 1807.03748},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\BEXEB8IG\\Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:application/pdf},
}



@article{tian_what_2020,
	title = {What {Makes} for {Good} {Views} for {Contrastive} {Learning}?},
	url = {http://arxiv.org/abs/2005.10243},
	abstract = {Contrastive learning between multiple views of the data has recently achieved state of the art performance in the ﬁeld of self-supervised representation learning. Despite its success, the inﬂuence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classiﬁcation accuracy. As a byproduct, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classiﬁcation (73\% top-1 linear readout with a ResNet-50)1.},
	language = {en},
	urldate = {2021-05-05},
	journal = {arXiv:2005.10243 [cs]},
	author = {Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
	month = dec,
	year = {2020},
	note = {arXiv: 2005.10243},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Tian et al. - 2020 - What Makes for Good Views for Contrastive Learning.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\7XCI74ET\\Tian et al. - 2020 - What Makes for Good Views for Contrastive Learning.pdf:application/pdf},
}


@article{hjelm_learning_2019,
	title = {Learning deep representations by mutual information estimation and maximization},
	url = {http://arxiv.org/abs/1808.06670},
	abstract = {This work investigates unsupervised learning of representations by maximizing mutual information between an input and the output of a deep neural network encoder. Importantly, we show that structure matters: incorporating knowledge about locality in the input into the objective can signiﬁcantly improve a representation’s suitability for downstream tasks. We further control characteristics of the representation by matching to a prior distribution adversarially. Our method, which we call Deep InfoMax (DIM), outperforms a number of popular unsupervised learning methods and compares favorably with fully-supervised learning on several classiﬁcation tasks in with some standard architectures. DIM opens new avenues for unsupervised learning of representations and is an important step towards ﬂexible formulations of representation learning objectives for speciﬁc end-goals.},
	language = {en},
	urldate = {2020-12-02},
	journal = {arXiv:1808.06670 [cs, stat]},
	author = {Hjelm, R. Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
	month = feb,
	year = {2019},
	note = {arXiv: 1808.06670},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Hjelm et al. - 2019 - Learning deep representations by mutual informatio.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\BLBKU5W8\\Hjelm et al. - 2019 - Learning deep representations by mutual informatio.pdf:application/pdf},
}



@article{gutmann_noise-contrastive_nodate,
	title = {Noise-{Contrastive} {Estimation} of {Unnormalized} {Statistical} {Models}, with {Applications} to {Natural} {Image} {Statistics}},
	abstract = {We consider the task of estimating, from observed data, a probabilistic model that is parameterized by a ﬁnite number of parameters. In particular, we are considering the situation where the model probability density function is unnormalized. That is, the model is only speciﬁed up to the partition function. The partition function normalizes a model so that it integrates to one for any choice of the parameters. However, it is often impossible to obtain it in closed form. Gibbs distributions, Markov and multi-layer networks are examples of models where analytical normalization is often impossible. Maximum likelihood estimation can then not be used without resorting to numerical approximations which are often computationally expensive. We propose here a new objective function for the estimation of both normalized and unnormalized models. The basic idea is to perform nonlinear logistic regression to discriminate between the observed data and some artiﬁcially generated noise. With this approach, the normalizing partition function can be estimated like any other parameter. We prove that the new estimation method leads to a consistent (convergent) estimator of the parameters. For large noise sample sizes, the new estimator is furthermore shown to behave like the maximum likelihood estimator. In the estimation of unnormalized models, there is a trade-off between statistical and computational performance. We show that the new method strikes a competitive trade-off in comparison to other estimation methods for unnormalized models. As an application to real data, we estimate novel two-layer models of natural image statistics with spline nonlinearities.},
	language = {en},
	author = {Gutmann, Michael U and Hyvarinen, Aapo},
	pages = {55},
	file = {Gutmann and Hyvarinen - Noise-Contrastive Estimation of Unnormalized Stati.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\A8NCV3NN\\Gutmann and Hyvarinen - Noise-Contrastive Estimation of Unnormalized Stati.pdf:application/pdf},
}


@article{chen_simple_2020,
	title = {A {Simple} {Framework} for {Contrastive} {Learning} of {Visual} {Representations}},
	url = {http://arxiv.org/abs/2002.05709},
	abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming AlexNet with 100X fewer labels.},
	language = {en},
	urldate = {2021-05-05},
	journal = {arXiv:2002.05709 [cs, stat]},
	author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.05709},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Chen et al. - 2020 - A Simple Framework for Contrastive Learning of Vis.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\VIM3N5A3\\Chen et al. - 2020 - A Simple Framework for Contrastive Learning of Vis.pdf:application/pdf},
}

@article{he_momentum_2020,
	title = {Momentum {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1911.05722},
	abstract = {We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning [29] as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-ﬂy that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classiﬁcation. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.},
	language = {en},
	urldate = {2021-05-05},
	journal = {arXiv:1911.05722 [cs]},
	author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
	month = mar,
	year = {2020},
	note = {arXiv: 1911.05722},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {He et al. - 2020 - Momentum Contrast for Unsupervised Visual Represen.pdf:C\:\\Users\\fjsae\\Zotero\\storage\\NU929CYR\\He et al. - 2020 - Momentum Contrast for Unsupervised Visual Represen.pdf:application/pdf},
}



@article{larochelle_neural_nodate,
	title = {The {Neural} {Autoregressive} {Distribution} {Estimator}},
	abstract = {We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size. Our model circumvents this diﬃculty by decomposing the joint distribution of observations into tractable conditional distributions and modeling each conditional using a non-linear function similar to a conditional of an RBM. Our model can also be interpreted as an autoencoder wired such that its output can be used to assign valid probabilities to observations. We show that this new model outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM.},
	language = {en},
	author = {Larochelle, Hugo and Murray, Iain},
	pages = {9},
	file = {Larochelle y Murray - The Neural Autoregressive Distribution Estimator.pdf:C\:\\Users\\Javier\\Zotero\\storage\\D95VTJVB\\Larochelle y Murray - The Neural Autoregressive Distribution Estimator.pdf:application/pdf},
}


@article{uria_rnade_2014,
	title = {{RNADE}: {The} real-valued neural autoregressive density-estimator},
	shorttitle = {{RNADE}},
	url = {http://arxiv.org/abs/1306.0186},
	abstract = {We introduce RNADE, a new model for joint density estimation of real-valued vectors. Our model calculates the density of a datapoint as the product of onedimensional conditionals modeled using mixture density networks with shared parameters. RNADE learns a distributed representation of the data, while having a tractable expression for the calculation of densities. A tractable likelihood allows direct comparison with other methods and training by standard gradientbased optimizers. We compare the performance of RNADE on several datasets of heterogeneous and perceptual data, ﬁnding it outperforms mixture models in all but one case.},
	language = {en},
	urldate = {2021-07-02},
	journal = {arXiv:1306.0186 [cs, stat]},
	author = {Uria, Benigno and Murray, Iain and Larochelle, Hugo},
	month = jan,
	year = {2014},
	note = {arXiv: 1306.0186},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 12 pages, 3 figures, 3 tables, 2 algorithms. Merges the published paper and supplementary material into one document},
	file = {Uria et al. - 2014 - RNADE The real-valued neural autoregressive densi.pdf:C\:\\Users\\Javier\\Zotero\\storage\\4HM63HHH\\Uria et al. - 2014 - RNADE The real-valued neural autoregressive densi.pdf:application/pdf},
}

@book{cover_elements_1991,
	address = {New York},
	series = {Wiley series in telecommunications},
	title = {Elements of information theory},
	isbn = {978-0-471-06259-2},
	language = {en},
	publisher = {Wiley},
	author = {Cover, T. M. and Thomas, Joy A.},
	year = {1991},
	keywords = {Information theory},
	file = {Cover y Thomas - 1991 - Elements of information theory.pdf:C\:\\Users\\Javier\\Zotero\\storage\\NTM35IBQ\\Cover y Thomas - 1991 - Elements of information theory.pdf:application/pdf},
}
