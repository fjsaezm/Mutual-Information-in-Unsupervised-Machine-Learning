En este trabajo, trataremos de exponer cómo ha ido evolucionando el \emph{aprendizaje de representaciones} desde los primeros métodos usados hasta los nuevos marcos usados en este campo. En este trabajo, realizaremos un estudio \textbf{teórico} de los conceptos necesarios para aproximarnos al problema de aprendizaje de representaciones (partes 1 a 3) y, a continuación y de forma algo más \textbf{práctica}, presentaremos algunos marcos de trabajo utilizados y realizaremos una serie de experimentos utilizando estos marcos (partes 4,5).

La parte \textbf{teórica} describe y profundiza los conceptos más importantes y en los que se fundamenta la parte prática.

En la \textbf{primera parte} se comienza haciendo una introducción y motivación profunda al tema (capítulo 1), y se sigue (capítulo 2) describiendo los conceptos básicos de teoría de probabilidad que se van a usar para exponer la teoría del trabajo, como el concepto de variable aleatoria, independencia o esperanza de una variable aleatoria. A continuación (capítulo 3), se da la definición de la \emph{divergencia de Kullback-Leibler}, que será muy relevante pues será una de las formas que tengamos de expresar la \emph{Información Mutua}. Además, se darán algunos ejemplos de distribuciones de probabilidad que son usadas en el trabajo. 

Se realiza también (capítulo 4) una introducción a la inferencia estadística, introduciendo el concepto de verosimilitud y logaritmo de la función de verosimilitud. Por último (capítulo 5), se enuncia el problema de la  \emph{extimación de ruido contrastiva}, también muy relevante pues sobre él se definirán los marcos de trabajo del aprendizaje de representaciones.


La \textbf{segunda parte} está dedicada a presentar los conceptos más importantes de la \emph{teoría de la información} en los que se basa nuestro trabajo. Primeramente (capítulo 6), se expone el concepto de  \emph{entropía} y se dan ciertas propiedades de la misma. Estas propiedades son útiles pues cuando definimos (capítulo 7) la \emph{información mutua}, al definirse esta en función de la entropía, se pueden extrapolar sin ningún esfuerzo a propiedades de la información mutua. Además,también introducimos las tres principales \emph{cotas inferiores} para la información mutua: la \emph{cota inferior variacional}, la \emph{cota inferior contrastiva} y la cota inferior usando la\emph{representación Donsker-Varadhan} de divergencia de Kullback-Leibler. Estas cotas son muy útiles a la hora de hacer aproximaciones al valor real de la información mutua.

En la \textbf{tercera parte} se aproxima la formulación matemática al problema de \emph{aprendizaje de representaciones} (capítulo 8). Se presenta también de forma precisa el problema que queremos abordar. A continuación, se hace una introducción a los \emph{modelos generativos} (capítulo 9), modelos que tratan de obtener la distribución de probabilidad $P$ que sigue un conjunto de datos dado. Se además una introducción a los modelos auto-regresivos, que utilizan datos en ciertos instantes de tiempo para predecir valores futuros de esos datos. Más adelante (capítulo 10), se introduce el marco de trabajo del aprendizaje contrastivo en el que, fijado un conjunto de datos, se trata de discriminar entre datos obtenidos de dos distribuciones de probabilidad $P$ y $Q$ diferentes. Para ello, se utiliza la función de pérdida contrastiva. Por último en esta parte, se introducen las funciones de pérdida utilizando tripletas (capítulo 11), que son una generalización de la función de pérdida contrastiva.

En la \textbf{parte práctica}, se explican los principales marcos de trabajo que se utilizan y se exponen los experimentos realizados y resultados obtenidos.

La \textbf{cuarta parte} comienza haciendo una introdución al aprendizaje profundo (capítulo 12) resaltando el \emph{aumento de datos}, que proporciona nuevos ejemplos a partir de los datos obtenidos y que juega un papel crucial en el aprendizaje de representaciones. Entonces, se presentan dos redes siamesas:\emph{SimCLR} (capítulo 13) y \emph{Bootstrap your own latent (BYOL)} (capítulo 14), los dos marcos de trabajo que han surgido en el año 2020 para el aprendizaje de representaciones. En ambos casos, se da una motivación de por qué surgen, se explica la arquitectura que ambas siguen y las funciones de pérdida que utilizan cada una, y se comenta qué hiperparámetros pueden ser más relevantes a la hora de entrenar los modelos y obtener mejores representaciones para las tareas posteriores como clasificación o regresión.

En la \textbf{quinta y última parte} se exponen los experimentos realizados utilizando los marcos anteriores. Primeramente (capítulo 15), se exponen los objetivos que se persiguen mediante estos experimentos, que se resumen en adaptar los experimentos existentes a los recursos de los que se disponen. Además, se exponen las tecnologías utilizadas. Seguidamente (capítulo 16), se exponen primero los tres experimentos realizados utilizando SimCLR, un primero general, un segundo aumentando el tamaño y profundidad del \emph{encoder} del marco, y un tercero añadiendo una nueva capa de aumento de datos y preprocesamiento de los mismos. Los experimentos resultan exitosos, obteniendo en el tercero mejoras respecto al primero y resultados acordes a lo previsto. Lo mismo oscurre más tarde cuando realizamos dos experimentos utilizando BYOL, un primero en el que se demuestra empíricamente que la influencia que tenía el \emph{tamaño del batch} en SimCLR se pierde en BYOL, y un segundo en el que se amplía de nuevo el tamaño del encoder, obteniendo también resultados exitosos.

\textbf{Palabras clave:} \emph{información mutua}, \emph{estimación contrastiva de ruido}, \emph{entropía}, \emph{aprendizaje de representaciones}, \emph{redes siamesas}, \emph{pérdida usando tripletas}, \emph{aprendizaje profundo}, \emph{cotas inferiores}.
